{"cells":[{"cell_type":"code","execution_count":43,"metadata":{"id":"TEqeMg-kQL27","executionInfo":{"status":"ok","timestamp":1709356117757,"user_tz":360,"elapsed":449,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","from collections import Counter\n","from tqdm import tqdm\n","import pickle\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiMN29ibQUsq","executionInfo":{"status":"ok","timestamp":1709356270820,"user_tz":360,"elapsed":16507,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}},"outputId":"932dc87f-ffa6-4567-f0ad-d466278dd74f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# change to your path in google drive\n","YOUR_PATH_TO_WORKSPACE = \"/content/drive/MyDrive/MSAI/MSAI437 - Deep Learning/\""],"metadata":{"id":"WV4c7CkWQXqQ","executionInfo":{"status":"ok","timestamp":1709350254960,"user_tz":360,"elapsed":8,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.chdir(os.path.join(YOUR_PATH_TO_WORKSPACE, \"HW3\"))"],"metadata":{"id":"ITVA6UrrQdd_","executionInfo":{"status":"ok","timestamp":1709350255285,"user_tz":360,"elapsed":332,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UCxMlRgPQL2_","executionInfo":{"status":"ok","timestamp":1709350255285,"user_tz":360,"elapsed":6,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"outputs":[],"source":["def process_data(path):\n","    lines = open(path, 'r').readlines()\n","    data = []\n","    for line in lines:\n","        line = line.strip()\n","        if line.startswith(\"=\") and line.endswith(\"=\"):\n","            continue\n","        if line == \"\": continue\n","        data.append(line)\n","    return data\n","\n","def prepare_train_data(path, n=-1):\n","    data = process_data(path)\n","    tokens = []\n","    for text in data: tokens += text.split(\" \")\n","    counter = Counter(tokens)\n","    if n==-1: return tokens, counter, []\n","\n","    inversed_rank = counter.most_common()[::-1]\n","    need_to_replace = set([key for key, freq in inversed_rank if freq <= n])\n","    replaced_tokens = []\n","    for token in tokens:\n","        replaced_tokens.append(\"<unk>\" if token in need_to_replace else token)\n","    return replaced_tokens, Counter(replaced_tokens), need_to_replace\n","\n","def prepare_val_test_data(path, need_to_replace=[]):\n","    data = process_data(path)\n","    tokens = []\n","    for text in data: tokens += text.split(\" \")\n","    if len(need_to_replace) == 0:\n","      return tokens\n","    replaced_tokens = []\n","    for token in tokens:\n","        replaced_tokens.append(\"<unk>\" if token in need_to_replace else token)\n","    return replaced_tokens"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"qy_YVwb1QL2_","executionInfo":{"status":"ok","timestamp":1709353198198,"user_tz":360,"elapsed":296,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"outputs":[],"source":["class Wiki2(Dataset):\n","    def __init__(self, data_tokens: list, vocab: dict, seq_size: int=30) -> None:\n","        super().__init__()\n","\n","        self.data = self._index_all(data_tokens, vocab)\n","        self.seq_size = seq_size\n","\n","    def __getitem__(self, index):\n","        indexed_text = torch.tensor(self.data[index:index+self.seq_size]).long()\n","        indexed_target = torch.tensor(self.data[index+self.seq_size]).long()\n","        return indexed_text, indexed_target\n","\n","    def __len__(self):\n","        return len(self.data) - self.seq_size\n","\n","    def _index_all(self, data_tokens, vocab):\n","        set_keys = set(vocab.keys())\n","        return [vocab[token] if token in set_keys else vocab['<unk>'] for token in data_tokens]"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"oKpm_OD6QL3A","executionInfo":{"status":"ok","timestamp":1709351757770,"user_tz":360,"elapsed":307,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"outputs":[],"source":["class RNNModel(nn.Module):\n","    def __init__(self, vocab_size, embed_size=100, hidden_size=100, num_layers=1):\n","        super().__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.embed = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, text, hidden):\n","        # text: [batch_size, sequence_length]\n","        embedded = self.embed(text)  # [batch_size, sequence_length, embed_size]\n","        output, hidden = self.rnn(embedded, hidden)  # output: [batch_size, sequence_length, hidden_size]\n","        out = self.fc(output[:, -1, :])  # out: [batch_size, vocab_size], only feed final output of rnn to linear layer\n","        return out, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return torch.zeros(self.num_layers, batch_size, self.hidden_size)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFufLUwNQL3A","executionInfo":{"status":"ok","timestamp":1709355740999,"user_tz":360,"elapsed":1610,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}},"outputId":"76690e91-1877-4094-bbf1-755ddae67a6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["length of vocab: 13354\n","number of train tokens: 2007146\n","number of valid tokens: 209338\n","number of test tokens: 235854\n"]}],"source":["train_tokens, train_counter, need_to_replace = prepare_train_data(\"./dataset/wiki2.train.txt\", n=10)  # freq threshold: n\n","val_tokens = prepare_val_test_data(\"./dataset/wiki2.valid.txt\", need_to_replace)\n","test_tokens = prepare_val_test_data(\"./dataset/wiki2.test.txt\", need_to_replace)\n","print(\"length of vocab:\", len(train_counter))\n","print(\"number of train tokens:\", len(train_tokens))\n","print(\"number of valid tokens:\", len(val_tokens))\n","print(\"number of test tokens:\", len(test_tokens))\n","vocab = {key:i for i, key in enumerate(sorted(list(train_counter.keys())))}"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74uqwVn-QL3B","executionInfo":{"status":"ok","timestamp":1709355730014,"user_tz":360,"elapsed":1930045,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}},"outputId":"be1074b9-7301-4126-c115-805455ebc189"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","Epoch 1/20, Iter 3920/3920 - perplexity: 1090.8049: 100%|██████████| 3920/3920 [01:27<00:00, 44.71batch/s]\n","Epoch (Val) 1/20, Iter 408/3920 - perplexity: 455.0215: 100%|██████████| 408/408 [00:06<00:00, 64.06batch/s]\n","Epoch 2/20, Iter 3920/3920 - perplexity: 463.5960: 100%|██████████| 3920/3920 [01:27<00:00, 44.87batch/s]\n","Epoch (Val) 2/20, Iter 408/3920 - perplexity: 364.8809: 100%|██████████| 408/408 [00:06<00:00, 60.17batch/s]\n","Epoch 3/20, Iter 3920/3920 - perplexity: 375.0421: 100%|██████████| 3920/3920 [01:27<00:00, 44.91batch/s]\n","Epoch (Val) 3/20, Iter 408/3920 - perplexity: 305.8921: 100%|██████████| 408/408 [00:06<00:00, 59.75batch/s]\n","Epoch 4/20, Iter 3920/3920 - perplexity: 319.8277: 100%|██████████| 3920/3920 [01:27<00:00, 44.88batch/s]\n","Epoch (Val) 4/20, Iter 408/3920 - perplexity: 270.6893: 100%|██████████| 408/408 [00:07<00:00, 58.03batch/s]\n","Epoch 5/20, Iter 3920/3920 - perplexity: 283.8253: 100%|██████████| 3920/3920 [01:27<00:00, 44.67batch/s]\n","Epoch (Val) 5/20, Iter 408/3920 - perplexity: 246.0080: 100%|██████████| 408/408 [00:07<00:00, 56.12batch/s]\n","Epoch 6/20, Iter 3920/3920 - perplexity: 257.3768: 100%|██████████| 3920/3920 [01:27<00:00, 45.04batch/s]\n","Epoch (Val) 6/20, Iter 408/3920 - perplexity: 227.6596: 100%|██████████| 408/408 [00:07<00:00, 56.86batch/s]\n","Epoch 7/20, Iter 3920/3920 - perplexity: 237.7725: 100%|██████████| 3920/3920 [01:27<00:00, 45.02batch/s]\n","Epoch (Val) 7/20, Iter 408/3920 - perplexity: 214.5468: 100%|██████████| 408/408 [00:07<00:00, 56.82batch/s]\n","Epoch 8/20, Iter 3920/3920 - perplexity: 223.3234: 100%|██████████| 3920/3920 [01:27<00:00, 45.02batch/s]\n","Epoch (Val) 8/20, Iter 408/3920 - perplexity: 204.8192: 100%|██████████| 408/408 [00:07<00:00, 54.61batch/s]\n","Epoch 9/20, Iter 3920/3920 - perplexity: 211.8637: 100%|██████████| 3920/3920 [01:26<00:00, 45.20batch/s]\n","Epoch (Val) 9/20, Iter 408/3920 - perplexity: 197.0555: 100%|██████████| 408/408 [00:07<00:00, 56.88batch/s]\n","Epoch 10/20, Iter 3920/3920 - perplexity: 202.4358: 100%|██████████| 3920/3920 [01:32<00:00, 42.17batch/s]\n","Epoch (Val) 10/20, Iter 408/3920 - perplexity: 190.2665: 100%|██████████| 408/408 [00:06<00:00, 63.27batch/s]\n","Epoch 11/20, Iter 3920/3920 - perplexity: 194.7887: 100%|██████████| 3920/3920 [01:34<00:00, 41.60batch/s]\n","Epoch (Val) 11/20, Iter 408/3920 - perplexity: 184.7892: 100%|██████████| 408/408 [00:06<00:00, 60.51batch/s]\n","Epoch 12/20, Iter 3920/3920 - perplexity: 188.1149: 100%|██████████| 3920/3920 [01:31<00:00, 42.98batch/s]\n","Epoch (Val) 12/20, Iter 408/3920 - perplexity: 180.2197: 100%|██████████| 408/408 [00:07<00:00, 56.36batch/s]\n","Epoch 13/20, Iter 3920/3920 - perplexity: 182.4786: 100%|██████████| 3920/3920 [01:28<00:00, 44.16batch/s]\n","Epoch (Val) 13/20, Iter 408/3920 - perplexity: 176.2385: 100%|██████████| 408/408 [00:06<00:00, 59.59batch/s]\n","Epoch 14/20, Iter 3920/3920 - perplexity: 177.5180: 100%|██████████| 3920/3920 [01:27<00:00, 44.77batch/s]\n","Epoch (Val) 14/20, Iter 408/3920 - perplexity: 173.2622: 100%|██████████| 408/408 [00:07<00:00, 57.78batch/s]\n","Epoch 15/20, Iter 3920/3920 - perplexity: 173.1515: 100%|██████████| 3920/3920 [01:27<00:00, 44.57batch/s]\n","Epoch (Val) 15/20, Iter 408/3920 - perplexity: 169.9971: 100%|██████████| 408/408 [00:06<00:00, 62.40batch/s]\n","Epoch 16/20, Iter 3920/3920 - perplexity: 169.3006: 100%|██████████| 3920/3920 [01:28<00:00, 44.48batch/s]\n","Epoch (Val) 16/20, Iter 408/3920 - perplexity: 167.7278: 100%|██████████| 408/408 [00:06<00:00, 61.88batch/s]\n","Epoch 17/20, Iter 3920/3920 - perplexity: 165.6830: 100%|██████████| 3920/3920 [01:41<00:00, 38.75batch/s]\n","Epoch (Val) 17/20, Iter 408/3920 - perplexity: 165.4924: 100%|██████████| 408/408 [00:06<00:00, 60.20batch/s]\n","Epoch 18/20, Iter 3920/3920 - perplexity: 162.4933: 100%|██████████| 3920/3920 [01:29<00:00, 43.85batch/s]\n","Epoch (Val) 18/20, Iter 408/3920 - perplexity: 163.0568: 100%|██████████| 408/408 [00:06<00:00, 66.78batch/s]\n","Epoch 19/20, Iter 3920/3920 - perplexity: 159.5133: 100%|██████████| 3920/3920 [01:35<00:00, 41.11batch/s]\n","Epoch (Val) 19/20, Iter 408/3920 - perplexity: 161.0862: 100%|██████████| 408/408 [00:07<00:00, 55.64batch/s]\n","Epoch 20/20, Iter 3920/3920 - perplexity: 156.6854: 100%|██████████| 3920/3920 [01:28<00:00, 44.48batch/s]\n","Epoch (Val) 20/20, Iter 408/3920 - perplexity: 159.4727: 100%|██████████| 408/408 [00:07<00:00, 52.51batch/s]\n"]}],"source":["epochs = 20\n","batchsize = 512\n","\n","\n","train_dataset = Wiki2(train_tokens, vocab, 30)\n","train_loader = DataLoader(train_dataset, batchsize, shuffle=True, drop_last=True)\n","val_dataset = Wiki2(val_tokens, vocab, 30)\n","val_loader = DataLoader(val_dataset, batchsize, shuffle=False, drop_last=True)\n","\n","model = RNNModel(len(train_counter), 100, 100, 1).to('cuda')\n","criterion = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=1e-4, weight_decay=4e-5)\n","\n","train_perplexity, val_perplexity = [], []\n","\n","for e in range(epochs):\n","    model.train()\n","    mean_train_perplexity = 0\n","    with tqdm(total=len(train_loader), desc=f'Epoch {e+1}/{epochs}', unit='batch') as pbar:\n","        for i, (inputs, targets) in enumerate(train_loader):\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            hidden = model.init_hidden(batchsize).cuda()\n","\n","            optimizer.zero_grad()\n","            output, hidden = model(inputs, hidden)\n","            loss = criterion(output, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","            mean_train_perplexity += float(torch.exp(loss))/len(train_loader)\n","\n","            pbar.set_description(f'Epoch {e+1}/{epochs}, Iter {i+1}/{len(train_loader)} - perplexity: {float(torch.exp(loss)):.4f}')\n","            pbar.update(1)\n","        pbar.set_description(f'Epoch {e+1}/{epochs}, Iter {i+1}/{len(train_loader)} - perplexity: {mean_train_perplexity:.4f}')\n","\n","    model.eval()\n","    mean_val_perplexity = 0\n","    with tqdm(total=len(val_loader), desc=f'Epoch (Val) {e+1}/{epochs}', unit='batch') as pbar:\n","        for i, (inputs, targets) in enumerate(val_loader):\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            hidden = model.init_hidden(batchsize).cuda()\n","\n","            output, hidden = model(inputs, hidden)\n","            loss = criterion(output, targets)\n","\n","            mean_val_perplexity += float(torch.exp(loss))/len(val_loader)\n","\n","            pbar.set_description(f'Epoch (Val) {e+1}/{epochs}, Iter {i+1}/{len(train_loader)} - perplexity: {float(torch.exp(loss)):.4f}')\n","            pbar.update(1)\n","        pbar.set_description(f'Epoch (Val) {e+1}/{epochs}, Iter {i+1}/{len(train_loader)} - perplexity: {mean_val_perplexity:.4f}')\n","\n","    train_perplexity.append(mean_train_perplexity)\n","    val_perplexity.append(mean_val_perplexity)"]},{"cell_type":"code","source":["plt.plot(train_perplexity, label='train-perplexity')\n","plt.plot(val_perplexity, label='val-perplexity')\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Perplexity\")"],"metadata":{"id":"l1bHgoqBkDda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = Wiki2(test_tokens, vocab, 30)\n","test_loader = DataLoader(test_dataset, batchsize, shuffle=False, drop_last=True)\n","\n","model.eval()\n","mean_test_perplexity = 0\n","with tqdm(total=len(val_loader), desc=f'Test', unit='batch') as pbar:\n","    for i, (inputs, targets) in enumerate(val_loader):\n","        inputs, targets = inputs.cuda(), targets.cuda()\n","        hidden = model.init_hidden(batchsize).cuda()\n","\n","        output, hidden = model(inputs, hidden)\n","        loss = criterion(output, targets)\n","\n","        mean_test_perplexity += float(torch.exp(loss))/len(test_loader)\n","\n","        pbar.set_description(f'Test, Iter {i+1}/{len(test_loader)} - perplexity: {float(torch.exp(loss)):.4f}')\n","        pbar.update(1)\n","    pbar.set_description(f'Test, Iter {i+1}/{len(test_loader)} - perplexity: {mean_test_perplexity:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2PzRumwT8Et","executionInfo":{"status":"ok","timestamp":1709355789772,"user_tz":360,"elapsed":7662,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}},"outputId":"97ddce79-4c9e-46de-bfc6-0fb69e7bbff3"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["Test, Iter 408/460 - perplexity: 141.4453: 100%|██████████| 408/408 [00:07<00:00, 56.54batch/s]\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"./checkpoint.pt\")\n","f = open(\"./vocab.pkl\", 'wb')\n","pickle.dump(vocab, f)\n","f.close()"],"metadata":{"id":"1I746Fp3hHk_","executionInfo":{"status":"ok","timestamp":1709355839151,"user_tz":360,"elapsed":374,"user":{"displayName":"Yijie Li","userId":"02178799734448805214"}}},"execution_count":42,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}